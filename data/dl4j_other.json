{"ids": ["DUPEg60s", "qfuKYQ1L", "pFFxH8N2", "VgMh6Aqb", "Grg9jWwq", "kDCofX1Y", "7RN2EAY9", "mByM01Ov", "Ts8qe6XR", "32eZHrBU", "XWCvNiiH", "x8SH0k82", "T81QtTvE", "RLHipSa8", "nUAAVI2V", "YzAGlDY4", "PGy3sKr0", "HcLkpcpq", "aWccEQSf", "FKWZIe6f", "Oy8elgTS", "fvs178MT", "4GRvCGeE", "qsYRSQVq", "dt0Nq69N", "mhYPKoIC", "aPHfgvMl", "eTQEbpcr", "Ii1zo1z5", "M9bf165k", "Ko72N84y", "hKLWtk7k", "PZ8UqwqB", "RygwjZVV", "1koUi3r9", "921TISZp", "6NdOjCtq", "WKFOBpfv", "UtYIkTy7", "CUjirTmN", "fu7MNY3z", "Y75yl0C2", "UtFqfJEK", "Es8sjjgF", "NFoJnIgF", "r1MFLz1C", "4BTPHn4i", "JiycwjNQ", "HqUdbpsV", "NExcbBWo", "vWJWOZyl", "q4btmLTn", "Vs1RvpSy", "DKGN8eb4", "nYlqipRk", "JQ1Wc7IK", "ctt41C1y", "4s5GkaPE", "QgZZhahb", "Tz1juqXE", "jNaVfHpw", "AMLlvhjZ", "clbA7YA4", "F4ljwlJN", "2eBahhAs", "rv2GJ40F", "KitptkxW", "qUOYWmJu", "XsQo1Ngg", "AOmoXo4w", "apddVjsE", "QWTdpZi6", "Anvvoxmp", "PSrKCEsx", "DTmSBkjM", "ffeZlDS4", "UIKKfQxM", "jU5mjhJh", "pXEjbxOP", "I4QKaa3I"], "dialog": [["how to frame a network which reads paragraph and answer question from that?", "d4jnewbie: Have you set up the examples and read trhough the code? ", "Start there [<-LINK->] ", "i have done all these but this example doesn't statisfy my usecase.", "got held up how to proceed", "d4jnewbie: question answering systems are alotmore complicated than most of our examples... you're going to have to research the deep learning literature and build it yourself", "can you suggest  some steps to achieve question answering system from paragraph?", "agibsonccc: can you suggest some steps to achieve question answering system from paragraph?", "d4jnewbie: I\u2019d suggest to go to arxiv.org as first step", "your question doesn\u2019t have simple answer"], ["could you point to an example /doc how to provide dataset with multiple labels  (e.g. RecordReaderDataSetIterator ). The dataset has several labels, each can be yes or no (1 /0) , multiple \"yes\" could be set.", "vedina: the iterator does that out of the box", "You just specify the number of labels and you're set"], ["Is it possible to build a (standard) fully recurrent neural network with backpropagation through time in DL4J?", "yes", "Because the documentation justs says something about lstm", "oh, you mean non-lstm", "hmm, not sure about that actually", "relue: we only do lstms", "and their bidirectional cousin", "Ok thanks :)", "relue: 'vanilla' RNNs wouldn't be hard to implement, but we haven't needed them yet so haven't built them", "It shouldnt be too hard to implement that. It just needs the unfolding of rnn into an mlp and then do slightly modified BP", "But maybe deep rnn aren't suitable for practical use, just researching deep rnn for time series prediction", "relue: LSTM is very useful for time series prediction too"], ["actually while we're on the topic, does remote UI reporting write to file or does the UI put the stats in memory?", "crockpotveggies: defaults to in memory though, but you can use either", "one sec", "hmm, I wonder if that was the cause of my earlier problem", "crockpotveggies: I understand it that you can choose, either memory or file", "[<-LINK->] ", "[<-CODE->] what does attach do?", "to the UI, you don't actually have to display the data when collecting it", "nifty", "I assume a single storage can handle multiple training instances?", "yep, that's the idea", "currently all remote UI info will be posted to a single storage instance", "good to know, that's going to save me a lot of headache :)"], ["Hey guys, I have one last question around spark's word2vec implementation (newest version). Is there anyway to update existing weights, like the standalone word2vec version? For example, if I start with a corpus of 1 gb, then add 500 more mbs at a later time, can it do so without overwriting the existing vocab and inMemoryLookupTable? If not, is there a way to merge two lookup tables? (I know you can add vocab cache, but I don't see anything for the inMemoryLookupTable).", "dmmiller612: there are methods for that, but problem isn't really a merge of two tables, but merge of two huffman trees.", "ah, I didn't seen anything that did that in the word2vec implementation. Is it apart of the nlp package?", "dl4j-spark-nlp", "thanks"], ["I have a question about how nd4j find the location of native .so files.  All native .so files are packaged into a nd4j-native-0.7.0-linux-x86-64.jar file. But when javacpp loads .so libraries, normally it needs java.library.path to find the .so libraries. But I didn't find this setting.  so I wonder how javacpp find the location of native .so files.", "xuzhongxing: it's based on the classpath", "javacpp has a loader class", "But when I was trying a simple example of javacpp, it said UnsatisfiedLinkError. I have to set LD_LIBRARY_PATH to suppress it. I have the .so file on my classpath.", "AlexDBlack: I figured it out:", "I need to include platform name in the directory in the jar file that contains the .so files.", "Thanks for pointing me to the source code of javacpp", "sorry, @ the wrong person.@agibsonccc"], ["Good Morning (again!) Trying to run arbiter and trying to figure out how to create the [<-CODE->]; but this is not splitting the dataset correctly. How to I create a  DataProvider from a RecordReaderDataSetIterator?", "jvence: you'd want to split the data yourself", "jvence:  [<-LINK->] if you pre save the datasets you can use this. There's also balance minibatches: [<-LINK->] ", "agibsonccc: Can I use SplitTestAndTrain?", "not really, unless you have the whole dataset in memory", "you could go through the iterator and randomly do split test train and save the results", "agibsonccc: when training my model, I use  SplitTestAndTrain on a RecordReaderDataSetIterator (after applying NormalizerMinMaxScaler) to load the data. Does this not work?", "well so again, you till have the problem of not having the whole dataset in memory", "you could do split test and train on the batches and concatneate", "my batch size is the entire data set so I should be fine", "then yeah split test and train will work"], ["How can I make read data format .h5 (HDF5) into DataSetIterator? The data structure of my .h5 file is like this \"/GroupA/Group*/(-DataSet1 -DataSet2 -DataSet3)\". I can read it easily and assign it to NDArray but I dont how to assign it to DataSetIterator.", "PhavMakara_twitter: you can use the new javacpp based presets [<-LINK->] ", "you would use that with dataset.load. if you can do a chain of saves in to a file this should work :D. What I would maybe consider doing if you can would be prepending an int and reading that in to represent the count of the number of datasets. then you can just chain save and load calls", "Okay let me clarify your answer. You suggest me to chuck my own data without using DataSetIterator right? ", "I never use that javacpp before. It probably takes me some time to really get what you suggest.", "PhavMakara_twitter: it's just java bindings for the c++ hdf5, same api", "your goal is to basically get an input stream and an outputstream that you can write and read raw bytes from", "I just told you the binary format to use from there :D"], ["Within class LenetMnist Example in deeplearning4j example package, when you train the model, how can you specify the input data label to fit the model? I only see you using model.fit(inputData) without specific the label with it.", "DataSet contains input and label fields", "But if have separate dataset how can I combine them, for example by dataset input is 3 dimension and output is 1 dimensional output", "Based on this link [<-LINK->] , Can I just declare it like this Dataset input = new Dataset(input,Label) while both input and label are NDArray with different dimension", "input and label fields can be any INDArrays (that are appropriate for the network you are training, anyway)", "and yes, you create it using that constructor", "Thank"], ["AlexDBlack: alex could you please explain the meaning of iteration number in the BasicRNNExample?", "suppose you have 3 examples: A,B,C in a DataSetIterator.iterations(1): fit(DataSetIterator) does training like ABC.iterations(3): fit(DataSetIterator) does training like AAABBBCCC", "usually .iterations(1) is what you want", "that was an example contributed by the community fwiw", "thank you.", "So in that example, it is similar to the epoch parameter", "if all data is in one DataSet object: then .iterations(x) and fitting for x epochs are identical", "in general, similar to epochs, but different order", "repeated order like that isn't usually a good idea", "I see.", "In what situation setting iterations > 1 makes sense?", "not many, to be honest. full batch/dataset learning (usually only possible on very small data sets), andmaybeif data loading is very costly", "I seeff"], ["the autoencoder example is quite simple... so I have still plenty of questions. first of all, there are many types of autoencoders such as Denoising autoencoder, Sparse autoencoder, Variational autoencoder, Contractive autoencoder... which does DL4J support?do I need to do something special to make an autoencoder that is  Denoising autoencoder, Sparse autoencoder, Variational autoencoder or Contractive autoencoder?", "variational autoencoder now available at current master", "alex merged it few days ago", "nice!", "daredemo: There are small special things for each of the subtypes of autoencoders.  Sparse has a penalty (usually L1) which encourages sparse activation in the inner-most hidden layer.  Denoising adds noise on the input and attempts to reconstruct a noise free output.  Variational autoencoders instead learn a mean and standard deviation instead of an explicit internal state, then randomly generate a hidden state from those values and reconstruct.", "Of the bunch, denoising is perhaps the easiest to train, since you just had to do train(myExamples + noise, myExamples)", "JosephCatrambone: I know the differences in the autoencoders. just wondering how to implement them in DL4J (for example the L1 stuff that you mentioned)", "Ah.  Sry.  I misunderstood.", "In this respect, I can't really help.  I'm here for the ND4j stuff.  ;)", "I mean, I know, but I don't know the exact math behind them", "'tiz OK :D"], ["Word2Vec: I have 2 words as vector representations. After I averaged them, I have one vector representation. How do I lookup the table with the vector representation?", "the same way wordsNearest", "it accepts vectors as well as words", "raver119: where can I find a decent documentation containing all the functions relevant to Word2Vec?Thanks!", "in javadoc [<-LINK->]"], ["downloaded the most recent deeplearning4j/examples. The following occurs when I run the examples if they are related to mnist. Not sure if this is a known issue or not.o.d.b.MnistFetcher - Downloading mnist...<CODE>", "thewzhang: that's just a network connection problem", "try again, and if necessary, delete the MNIST directory in your home directory", "AlexDBlack: , thank you! I removed the MNIST directory and now it is working. Do not feel that it is a network connection problem.", "it was most likely caused by a network connection issue while downloading", "thanks, Alex. MNISTAnomalyExample worked and MLPMnistTwoLayerExample is working.", "great"], ["I\\'m reading about the rnn stuff and it says \"It is not possible to change the number of examples between calls of rnnTimeStep\". I'm trying to understand this: to make a prediction, I need the previous state, but if I call rnnClearPreviousState(), this clears the previous... which now allows me to use any number of examples I want... but because previous state was cleared... this means that I'm back in the beginning? let's say I have daily data, and I do at first 2 examples (days) at a time... after some time I've reached say Thursday and could predict Friday, but if I do rnnClearPreviousState(), then I'm back to Monday?", "it's pretty uncommon that you want to predict the next steps of some number of time series,and start predicting for a new time series at the same time", "it gets hard to track, too", "in principle: you can manually set the state. it's just arrays, and adding more examples means a larger dimension 0 for the state", "I mean is performance so critical that you really need to do that? if not, I'd suggest keeping them separate", "AlexDBlack: I'm not yet even trying to optimize, I'm not sure what it is doing or supposed to be doing... for example, if I do single step, then I get next day, right? if I do say 2 examples/days, then I predict the day after tomorrow? or still just tomorrow?", "have you read this? [<-LINK->] and the javadoc? [<-LINK->] ", "that's exactly what I'm reading (not yet the javadoc though)", "so 3 examples would mean tomorrows prediction in 3 locations?", "right, if you feed in an array with size(0) == 3, then that's just a batched prediction for 3 separate examples", "works exactly the same way as a training minibatch or standard forward pass in that respect", "OK, got it now, thanks@AlexDBlack", "sure, np"], ["still struggling to grasp the concepts to design a RNN networklet\\'s say I wanted to detect motions/swipes on \"touch pad\" that consists of n x n sensors that record the state at a given interval. The users obviously do not make the motions identically, including the speeds might be different. So, now I have two questions:1) should I use a single n x n conv layer as input? or should I use some mega large input that contains all the n x n frames until the slowest motion is completed?2) if I used just single n x n as input, how should the training labeling be done? logically it seems that the label should be when the motion is completed, that is in the end, but should the other frames from the first to the last frame also be labeled the same?", "daredemo: You could use a CNN to obtain a single vector representation and then feed that into an RNN. Another approach I think of is to capture touchpad \"activation\" in a single matrix and let them decay with each timestep, so that most recent values will be 1 and old values will be close to zero and then apply a CNN to that single matrix. The problem with tihs approach is that you would need to detect start and end (maybe with another net?)", "Paranaix: could you elaborate on this? do you mean by this that would build input layer that is m frames deep? [m x n x n] if my frame is [n x n ]? because this seems a bad idea, as it would require a lot of computing each step. some kind of hidden Markov model would be preferred, when I would only need to know the previous state, not m previous states", "daredemo: [n x n] -- CNN --> [m x 1] ---> RNN", "Paranaix: so that\\'s my \"1)\" with single [n x n] input?", "Yes but with an RNN afterwards", "Or did you mean that?", "of course, the beginning of my question implied that I'm doing RNN :D", "but if I use the [ n x n ] input, I\\'m then struggling with the \"2)\": how do I label my data?when the finger touches the middle of the touch pad, it could then move anywhere, up down left right; so it would seem strange to label it as \"up\" even if it is part of \"up\" motion... or should I? or should those intermediate steps be all classified as \"meh?\" :D or some intermediate classifier like \"doing up\" and only the end would be \"up\"?", "in other words, in the sequence of \"up\", should I classify the first frame also as \"up\" for training?"], ["daredemo: \"the webpage talk about input and output masks but only show one layer... is the input mask for only the rnn output layer? or is that for the first/input layer even if you have other non-rnn layers before it?\"output mask is used only with RnnOutputLayerinput mask really only applies if you have one or more dense layers before your RNN layers, as say tanh(0 x weights + bias) != 0 in general... for RNN layers only, it\\'s equivalent to just setting the masked inputs to 0 anyway. So strictly speaking, you don\\'t need input mask for RNN-only networks (but we have no way of knowing that at data loading time)", "AlexDBlack: only dense layers? not in case of CNN?", "daredemo: honestly? we probably should have it for CNNs as well... but I don't think it's in there currently", "AlexDBlack: I'm just asking questions :D I know nothing :D trying to figure the RNN part out, but probably won't have any meaningful training data before next week", "daredemo:  [<-ISSUE->] fyi"], ["Guys help please. I don't understand what each gate in LSTM architecture produce. Is it a number or a vector? If I'm not wrong  sigmoid function ALWAYS produces only one number in range from 0 to 1. Or it is possible that every gate produces target vector that was obtained by applying sigmoid function to each element of  input vector?", "each gate produces a single number in range 0 to 1. you have 4 gates per LSTM unit, and multiple units per LSTM layer", "Is number of units == LSTM.nOut(numberUnits) of layer actually?", "so every LSTM block produces number and not a vector?", "fahman: yes", "by LSTM block I mean LSTM unit", "borjka: yes, it's the same as any other RNN (or, any other network in general) - each unit gives a single output/number", "it's all vectorized for implementation though, across all units", "really thank you! everything became so clear"], ["hello, in MNIST for experts example I can see pretrain called on builder. what kind of pretraining will be used if it is set to true", "Pretraining is special option for autoencoders/rbms", "can I use it to pretrain conv net weights using RBM automatically?", "I should be clearer: I want to do pretraining using RBM and then transfer the weights to conv net before starting backprop. will Builder.pretrain(true) do that for me?"], ["My computer does not have a GPU. Is it possible for me to build the whole project locally?", "See 2nd comment: [<-ISSUE->] ", "That means \"Building the CUDA Backend\" is not necessary?", "as long as you skip it you don't have to", "Is there a reason you're building from source though?", "You know you don't need to right?", "I want to change the loss function.", "You can add a custom one without compiling nd4j though", "for some special reasons.", "[<-ISSUE->]. It doesn't matter what they are :D there's an example right there of how to do it without compiling dl4j", "Our model is very special", "You can also do custom layers", "is there some instructions I can follow?", "on what? custom layers?", "yes", "Again - please listen to me when I say file an issue with what you're missing :D", "We have examples", "if you want step by step tutorials tell us what", "We have a dedicated person who does that stuff", "they read issues", "[<-LINK->] ", "custom layers and custom  loss functions", "We have basics", "the readme.me is right there for it", "readme.md*", "if you want more then tell us", "okay"], ["Has anyone used COSINE_PROXIMITY as a loss function for outputs and if yes, for what use case?", "fahman: re: cosine proximity - I've never used it (but yes, it's all tested/gradient checked)... was built partly for our keras import functionalitybut I believe this is one application: [<-LINK->]  [<-LINK->] (compare eq 3 vs the comments of the mathematical form in the code comments)", "Yes I thought I could use it to loss compare word embeddings, but somehow I cant manage to set other hyperparameters. I get always NaN as score", "Gonna check the paper", "and re: masking arrays -@eralyhas explained it well... just to reiterate: the net always outputs something at each time step, even with maskingyou can use this to manually zero them if you want: [<-LINK->] during training we use the mask to set the errors (loss function gradients) to 0 - the network's predictions are thus ignored for those time steps", "Ye@eraly's explanation was good, didn't realized the masking worked that way but its perfectly fine"], ["im stuck after reading in the data..like how to pass the data to a CNN..any input into that.", "well, do you have DataSet objects yet? that's why I was saying use CSVRecordReader + RecordReaderDataSetIterator, then it's pretty straightforward", "ok. i will try that..", "can i get back if i have any problem ?", "sure. ", "start with this: [<-LINK->] then adapt it based on my earlier comments (delimiter, regression, etc)", "ok..thank you.. i was following that example to read in the data. I will explore further and will try. Thank you"], ["Hi. Is there a place for deeplearning pre-trained model (not only model, but weights)? I am looking for a way to use pre-trained VGG16 in dl4j. Any pointer?", "benqua: We don't have weights yet. The plan is to add that to: [<-LINK->] when we do"], ["is there anything in datavec thta would help me create separate feature/label files, like the ones used in the UCI classification example, or will I have to create them \"manually\" for my own time series?", "dan-lind: you'd have to do that manually but if you have a vision for how such a feature would work feel free to file an !issue", "something like that wouldn't be out of the scope of datavec"], ["anyone know what would be a common cause of multiLayerNetwork.output() returning NaN?", "thanks guys"], ["hi,", "Good Evening.", "mrseven7seven: @iw876 guys, just go straight to your questions. no need to wait till someone replies to your abstract \"hi!\"", "you'll get answers faster this way :)", "how to get an image (with rank 4) in a RBM? (channels = 1) my first idea is to flat dimensions 3 and 4 to form img_heigth*img_width columns, bad idea?", "rbm kinda expects vector as input", "so just flatten your images. there's method available for that, Nd4j.toFlattened()", "ok, thanks"], ["is it somehow possible to reverse engineer the filename from an instance in a DataSetIterator? filename of video/image etc.", "someonedeep: yes, you have to enable meta data tracking and then you can get it from the DataSets"], ["HI How to run deeplearning4J on hadoop by using mapreduce? Is there any examples?", "there\u2019s none, mr isn\u2019t supported anymore", "spark is the way to go", "xuzonghan: we had it at 1 point but no one was willing to pay for it", "it was supported earlier, but ^^^", "we have salaried engineers working on dl4j", "if something is a maintenance burden we cut it", "we did that with spark.ml too", "same thing", "maintaining 2 versions of spark wasn't good for us", "OK, I will switch to spark too :)"], ["did I just dream that there were AWS AMIs available for dl4j? Can't find any. Perhaps it's just not in my region", "dan-lind: we don't have anything up to date up there - we do have the docker containers though: [<-LINK->] "], ["A further question.  I could not make/build the dl4j code base using IntelliJ.  For example, I tried to make the deeplearning4j-nn module, and received the follow error message:", "truevines: did you follow the buildinglocally guide?", "That gives an end to end description of the setup", "[<-CODE>]  But I could build the dl4j-examples with no issues.", "You cant just import dl4j", "Its a 4 repo project", "Well duh", "Thats maven central ;)", "Big difference", "Seems like you skipped reading half of the docs :/", "[<-LINK->] Go through this first", "Sorry about that.  I thought I could just download the codebase and build it.", "Thanks for the information.", "We dont have snapshots yet so you neef yo setup c code :D", "I appreciate the effort but dl4j isnt just 1 codebase", "Wee bit more complex than that :D", "Thanks."], ["saudet: I did investigate that first but it seems that it doesn't really perform a sliding window, and then I'd have to convert each window to an indarray anyways which scares me", "crockpotveggies: well, it's kind of limited in what it can do, but it's fast"], ["Anyone can help see my question mentioned before? I set the iteration score listener. In 0.6.0, I can get the \"INFO\" of the iteration scores. But In 0.7.1, there is no such score INFO although I set the listener as well.", "AllenWGX: nothing changed There", "The only thing it would be is your logging", "Check the commit logs yourself if you want", "ok, I will check then."], ["I want to take compressed output from hidden layer of autoencoder.Some one suggested to use feedforward method for that but I'm not able to implement that.Pls help", "saurabhgangurde: literally theres' nothing else to do other than use feedforward... that gives you activations, which is exactly what you are asking for", "AlexDBlack: [<-CODE->]"], ["thank you, raver120, ", "I am reading deeplearning4j.org/quickstart, ", "your advice is so kind."], ["INDArray myArr = Nd4j.create(flat,shape,'c');    what does 'c' represent? and what is the difference between 'c' and 'f'? is there any material about this?", "[<-LINK->] see this", "yuimo123: it's general concept, C-ordering and Fortran ordering of elements within linear buffer", "aka Column-major and Row-major", "yes , i know. 'c' is c order ,and 'f' is f order", "why asked then?", ":)", "yuimo123: see [<-LINK->] ", "thanks.", "raver119: i am read the examples of nd4j, and i saw this. just ask"], ["Hi, everyone! I wanna to implement some missing functions in deeplearning4j (for example the multiplication operation in ElementWiseVertex). Is there a recommended way to do? Thank you!"], ["Anyone, implemented the word2vec and plot in a tsne graph .", "jageshmaharjan:  [<-LINK->] this is how you save tsne coordinates given a vector", "[<-LINK->] shows how our UI works", "jageshmaharjan: actually looking at the new UI..it looks we may need to implement the new tsne yet. Mind filing an !issue?", "agibsonccc: ,  i ran the former example before, but when i ran the later example, it consumes too much resource and my system stop responding. Thank you, "], ["i have still problem with understanding the batchsize. Let me explain, if i have 100 rows in train set and if i set batch size=100  means what? or setting batchsize=1 whta are the differences? i really still dont understand.", "K", "So I'm going to ask you read a book now :D  [<-LINK->]", "ok", "[<-LINK->] Go through this chapter and come back", "If you still have questions then we can talk", "I'm biased but I also wrote a !book", "thanks you very much", "More basic questions are answered in depth in the textbook", "ok"], ["Hi, how can i avoid score value being NaN during training? I think reporting NaN is undesired. Am i correct?", "!tuning", "!tuning", "hmmm", "If you want help from us prove to me your read our tuning docs first :D", "ok", "hakmesyo: go through those steps to your hyper parameters and what you've tried", ":)", "ok"], ["where can i find resources to understand how dl4j works interally?", "depends what you are looking for... it's a huge projectare you trying to implement a new type of neural network or something?"], ["hi", "I would like to use this code in java eclipse instead of  IntelliJ.  [<-LINK->] ", "v-mostafapour: there's nothing stopping you learn m2eclipse", "We won't support you if something hits a wall though", "We just don't use it", "So we can't really help with trouble shooting weird edge cases", "Beyond that follow traditional tutorials on the internet", "We aren't anything unique as long as you're using a build system", "thanks"], ["I'm having trouble trying to run an example project in Eclipse using Maven. How should I set the Maven project's launch configuration?", "There is nothing to set o_0", "If you are having problems it is likely related to being new to m2eclipse"], ["I am looking at the tsne and word2vec example. The code in TSNEStandardExample runs but does not plot anything at the end. The documentation on [<-LINK->] shows different code, ending in vec.lookupTable().plotVocab(tsne); which does not match what's in TSNEStandardExample. How do I get a plot of the result?", "bhomass: there\u2019s 2 options: either render to UIServer, or save to file as csv"], ["[<-LINK->]. hi, my computer config is i3 cpu, and 8G ram. but when i run this example of  Word2VecSentimentRNN, it keeps in this state for a long time. does that mean my computer config not enough?", "yes", "ram isn\u2019t enough", "\"i3\"?", "nvm cpu, ram is an issue here", "yes", "That will take forever to run anythin g:D", "ram too though", "i bet pc is swapping :)", "i asked u before, and you said you have run this in your lap, and it's 8G too ,hh", "Well it\\'s \"possible\"", "doesn't mean it's ideal :D", "adam's laptop is slightly more then 8g :)", "My travel laptop is 24GB", "ok, maybe i should get a better pc"], ["but Adam,  I have 1 million records (each has 10 time series), so that means I have to create 1 million files with 10 record in each . I don't think it is a good choice ....", "That's what I do too (for other reasons) and it gives me just a few hundred files (batches of 150 examples)", "(note that I need multiple files for a single example, multiple inputs and outputs, but that shouldn't matter otherwise)", "thanks Ede, I will try that"], ["I am trying to look into dl4j core source so I figure out how to use UiConnectionInfo. mvn download sources does not seem to work. is dl4j core source available? it would be helpful if someone at least put up a example that displays a plot on UiSever from beginning to end. otherwise, its time to give up", "bhomass: i\u2019ve posted you a link few hours ago", "link to repo  [<-LINK->] and download sources work as well", "it\u2019s kinda requirement", "ok, thank you", "it\u2019s right there at maven"], ["hi i use autoencoder to do feature processing. i get the model. but i find the input vector[0.000001, 0.3, 0.1143, 0.1786, 0.0, 0.0, 0.0, 1.0, 0.1257] is converted [0.00, 0.30, 0.11, 0.18, 0.00, 0.00, 0.00, 1.00, 0.13 ]by this method INDArray features = Nd4j.create(featureData);if i want to keep more decimal what should I do?", "it's just formatting on toString check with getDouble if you want", "ok thanks, i will try"], ["Hi! ", "I wanted to know what exactly the score of ScoreIterationListener specify? Is it the value cost function ? Because what I understand is the lower the score the better. So is it the cost function value or something else ?", "anandundavia: yes cost", "usually for a given batch", "Okay, thank you! :)"], ["When producing feature maps for convolution layer from previous pooling layer, to  my understanding, it's a full connection between all feature maps in pooling layer and one in convolution layer. Is this the groundtruth? It is according to \" [<-LINK->] \""], ["Hi ", "guys how are you"], ["How to get Layer instance of a specific vertex in ComputationGraph from custom BaseInputPreProcessor... ? I want to simply reach the weights of a layer (vertex) from another layer (vertex) during training..."], ["hey, I'm trying to import a model from keras, which seems to be working, but I don't really understand how to include the json and hdf file in the output jar. I put them in a resources folder that's a resource root and they are present at the root of the jar file, but I get a no file found exception"], ["I\\'m trying to use the video Classification example and have created a directory with mp4 videos (videos created with JavacV <CODE>. is there an mp4 codec that is recommended, or will any of the mp4 codec options suffice?"], ["I try to use  MatlabRecordReader but I can't understand how it works, anybody can explain me please?"], ["i spotted a pretrain boolean parameter in configuration. does this turn on Greedy Layer-Wise Unsupervised Pretraining for FFNN/RNN/CNN?"], ["Is the parameter \"learningRateScoreBasedDecayRate\" the same as learningRateDecayPolicy(LearningRatePolicy.Score).lrPolicyDecayRate ?"], ["Hi guys, with Deeplearning4J can I reproduce the results achieved articles about artistic style transfer? I found several implementation on Tensorflow (e.g. [<-LINK->] ). Is there any similar example or tutorial also for Deeplearning4j?"], ["I have a quick question about [<-LINK->] : Why is the prefetchBuffer set to 24 by default when the javadocs on prefetchBuffer says it should generally be the same as the number of workers? 24 seems really high with only 4 workers"], ["I want to solve the conflict, can I load libgomp from jars by modify nd4j's source code? if don't care the system, how to use javacpp load library from specify path before load from /usr/lib64", "Wouldn't setting LD_PRELOAD work?", "try building libnd4j from sources?,in worst case you'll just remove few pragmas, probably around declare simd", "liulhdarks: JavaCPP does that by default, something else is loading system libraries", "Wether I can remove the gomp from platform.preload in the linux-x86_64-nd4j.properties?", "but yes, like@agibsonccc says using LD_LIBRARY_PATH and/or LD_PRELOAD should force whatever to use what you want ;)", "ok I go to have try, thank you"], ["agibsonccc: how can I use wordVectors in seq2seq? [<-CODE->]", "gguogguo11: Could you give a full stack trace? I know you can't use gist in china so please use tool.lu if possible", "Screenshots aren't usually good either", "Tough to look at"], ["AlexDBlack: is there a way to calculate how much time it would take for Word2Vec to fit on some data? or even monitor what's going on? The reason why I am asking is because it has been more than 1 hour 20 minutes since the last log entry of  \"Starting vocabulary building...\" and 1 hour since it finished iterating over the data. PS: There were 58754 sentences for training the model", "KonceptGeek: with a small data set like that, it shouldn't take long you can add a VectorsListener instance to track progress... it should also log plenty of infobtw, ", "what version of dl4j are you using? and what backend?", "AlexDBlack: DL4J 0.7.0 with nd4j-native. There's Factorie and JSAT, both of them are regularly updated", "KonceptGeek: I'd suggest asking @raver119 about the word2vec performance issues (he should be online in about 6 hours maybe?)fwiw it should be significantly faster than 0.6.0, and your data isn't largefeel free to open an issue though with details and configuration - that might make things easier for us", "Sure@AlexDBlack. BTW, each sentence is a pretty big (almost a complete email/document) so that could possibly be slowing things down. And it's running on an 8core CPU."], ["Hi, there. I am new to dl4j and trying to run it on an spark on yarn cluster. Is there any configuration to do with the cluster? I cannot find any document about it.", "Marcteen:  [<-LINK->]  not sure how you missed this :D", "we mention yarn and the like right in there", "including the memory configuration", "our !examples have spark in them as well", "agibsonccc: Thanks. ", "I did notice that page but only find the guidance about application programming. I mean what exactly I need to do to give the cluster the right environment for running dl4j on spark? Such as the dependencies issue.", "It's just a spark job really, It's nothing different than what you already do. dl4j-spark is all you need", "you can look at our examples for that stuff"], ["Hi, I want to use DL4J to train my model, but my big concern is about training speed. I just read an article [<-LINK->] , seems DL4J is kinda slow. I am wondering whether this article is misleading somehow?", "Lancer66: that stuff is always out of date", "I would run your own benchmark", "Lancer66: all that stuff changes each and every release", "When was the paper even written? o_0", "[<-LINK->] ", "October 2016? not sure", "hmm..may", "Run your own benchmark If you do make sure to pre save the data: [<-LINK->] ", "OK, I will try to find out"], ["agibsonccc: , Can you look at the GenderDetection example code that I uploaded few days back for your review? Please let me know if I need to add more useful information into it to make it compatible with dl4j-examples.", "gks141270: I merged it already?", "Did you do another commit?", "No, I didn't. ", "Is it available in dl4j-examples now?", "[<-LINK->] ", "Oh..", "Great. I am happy to see it"], ["I made an app with dl4j and I want to deploy it on weblogic which is installed on a linux machine", "enache2004: should be straightforward what are you running in to?", "it complains about java.lang.UnsatisfiedLinkError: no jnind4j in java.library.path", "just use nd4j-native-platform then? make sure your dependencies are up to date too", "I use a previous version of dl4j 3.9", "O_O", "yup we've had 5-6 releases since then?", "maybe more", "I would like to test it that version because everything was fine on my machine", "I know..sorry", "we aren't liable for versions before this"], ["Hello everyone ! ", "Im also new to DL4J, tried some stuff, read about it and really like it :) . But what im currently struggling with is how to enable multi label data input in DL4J (an useful example would be tag prediction from an image) . For inputs with a single label i used the PathLabelGenerator, which was fine. Since Google and reading the docs did not help much (apart from redirecting to gitter :P ), i decided to ask here.", "Funny, someone else asked a very similar question a while ago about predicting multiple classes", "I think the only way is to take the n classes with the highest probabilities after the softmax step", "Maybe have a threshold on minimum probability and take all the classes with at least that probability", "But I take it you want to assign multiple labels to examples during training time. No idea how that would work honestly.", "Except maybe copying the examples that have multiple labels, one copy for every label you want to associate it with", "Do you mean using a PathLabelGenerator and having a path for each of the labels?", "CHemauer: I can't think a clean way to do that with the current built-in functionality. ", "open a github issue in datavec with your use case (i.e., where the labels are coming from - flat CSV? Map<URI,?>, etc) and we'll see what we can do, [<-LINK->] ", "Ok thanks for the fast replies!"], ["Is there an easy way to feed submats into a FFN and act on the parent image based on the prediction without having to write to disk?All the examples just show iterator examples. Do I have to manually write out the submats to create a DataSet/iterator?", "araymer: are you talkign about with using javacv?", "Yes", "You may want to look at NativeImageLoader which wraps javacv", "Have you seen that already?", "No, I'll take a look. Thanks", "araymer:  [<-LINK->] "], ["Hi I am having a little bit of trouble setting up all of the dependencies for spark. With this import line: [<-CODE->]", "anchitkolla: make sure all your dl4j versions are the same first of all", "You saw our !examples right?", "Those has the pom.xmls you need", "Usually it's just dl4j-spark with the right scala version. dl4j-spark_2.10 or dl4j-spark_2.11", "yeah all of my spark import statements work except for that line. I am getting cannot resolve \"paramavg\". ", "I will look more into that. Thanks Adam."], ["Hi, one quick question :)  you run UIExample from IntelliJ Idea as Java application or Maven something?", "what do you mean?", "I open the UIExample.java file all good", "I go run as Java application or I need to do do something like maven package?", "Run as java application", "ok, tnx!"], ["have you got a code example which simply has working code for tsne plot on word2vec output? the document only has snippet", "code for?", "for single method call?", "and the TSNEStandardExample.java does not plot", "i\u2019ve already pointed you to method you need", "like TSNEStandardExample.java, except one that actually put up a plot", "there\u2019s nothing more needed from you", "so you don't have such an example code"], ["[ERROR] Failed to execute goal org.apache.maven.plugins:maven-enforcer-plugin:1.4.1:enforce (enforce-default) on project dl4j-examples: Some Enforcer rules have failed. Look above for specific messages explaining why the rule failed. -> [Help 1]", "xtuyaowu: what are you trying to do?", "You shouldn't get that by default. What did you modif?", "i feel \"building from source\" attempt...", "probably :D", "I see \"dl4j-examples\" though"], ["I'm training a dnn + cnn model. The F1 score is around 50. But there are some warning that some classes are never predicted. i did a quite check. I guess that there are around 50% of training data is labeled as type A. There are 5 types. shall i create the dataset which is perfect balanced for 5 types?", "What do you mean \"dnn + cnn\" model? If you trained a conv net say that in plain english :D", "Beyond that yes, minibatches should always be balanced", "The intuition for minibatch learning comes from statistics", "If you have a minibatch it should ideally be as close to representative of your whole population as possible", "I mean danse layer + cnn. I used wrong word, i guess....", "The reason I ask about your model, is because batch size largely depends on dimensions of the data and kind of problem as well as number of labels", "Then say \"conv net\" :D", "so depending on how big your images are you could be like mnist where 1k is a good idea (small dimensions) or 32/64 like imagenet", "the label distribution will come down to batch size", "Ok. I merged a csv data and image data 100x100 pixel", "but as evenly distributed as you can get would be better, make sure to check our !tuning guide", "I read it, but want to learn more, for example about batch balancing", "thanks for the answer"], ["Hello~just 1 question. How can I contribute to document translation?", "you\u2019re welcome :)", "First of all - thank you for even offering.", "What language?", "I hope to contribute korean translation", "oh my god yes", "so it's just github pages", "[<-LINK->] ", "Here's our korean docs right here", "1 thing that would be IMMENSELY helpful would be if you could even just update our quickstart", "Before contributing on code, I thought I need to review dl4j project. Translating will be good to study.", "Oh sure.", "kepricon: is our engineer in korea", "so he can review", "we have 2 people there and little time :D so ANY help we can get is amazing", "Have you saw our korean channel?  [<-LINK->] ", "Feel free to ask questions there as well on wording and the like", "Thanks for help!"], ["I have a brain freeze about recurrent nets... All I'm trying to do is to evaluate a test set that is a timeseries data... and I can't figure out how to do it? do I have to feed the data one by one? because if I try to do it the \"normal\" way I get mismatch in label and predicted dimensions", "using the Evaluation class?", "you want evalTimeSeries for that", "oh", "for the net, just use .output(INDArray features)", "let me digest this for a moment", "[<-LINK->] actually, just do that MultiLayerNetwork.evaluate(DataSetIterator) if you can", "AlexDBlack: something is still going wrong, let me clean up my code and post it as gist", "so if you remove the StatsListener you'll still get that output", "you're saying the scores actually change if you do that?", "what I'm trying to do is recurrent with one input and with 4 classes: [<-LINK->] ", "daredemo: ah, use an RnnOutputLayer, not an OutputLayer", "AH! AlexDBlack: thanks a million", "sure, np"], ["raver119: Let me train a new model in 0.7.0 and test it out once... if that fails too I will share the models and file an issue", "just post configurations you have, i'll do it faster :)", "i know where to look there :)", "raver119:  [<-LINK->]", "how big is corpus? is it sentences or documents?", "documents = set of sentences. i.e. text file.", "documents", "amazing, thanks", "how big is it? how many documents, and what's average size of single document in bytes?", "We have 3 different models  : 1 with 2 lakhs docs, 1 with 32k docs and last one with 476 docs... all have average 10-12 sentencesa", "lakhs <- what's that word means?", "0.2 mil", "aha, thanks."], ["Hello, what happened to this page?", "Ettrai: there has been work to update the documents and that page was pulled. How did you get that link?", "Ettrai: that page was out of date, what page linked you to that?", "Ettrai: also, what did you need to know about our architecture?", "nyghtowl: @tomthetrainerI just used the search engine and a link provided in a paper. What I was trying to figure out is the parallelization strategies you are using", "Ettrai: what is the paper you were looking at?", "nyghtowl: it's from a double blind review so I cannot disclose it, sorry about that", "No problem - more just trying to understand where these links still exist", "sure", "Regarding the parallelization strategy, we apply the batch training approach where we divide the gradient updates by the batch size", "Thank you@nyghtowl. ", "I am trying to figure out those strategies given that I am new to neural networks but not new to parallel programming", "Ettrai: are you wondering about parallelism model for computations then?", "raver119: I think that's what I am looking for. It would be nice to get the idea of how you carry on this computation, reduce, and so on"], ["I learn some examples from named directories, unfortunately I only can see the indexes of the labels but not its names where loaded from, are these persisted in the model somewhere or do I have to care of it in the learning stage when loaded via FileSplit?", "thhart: that's where the record meta data comes in", "agibsonccc: But metadata I know for the datasets during learning, is there also metadata to store within a model for the labels?", "thhart: you'd have to track that yourself", "we are working on a more integrated pipeline api that will allow this to be a bit less opaque", "if you have any ideas for features feel free to open an issue"], ["@/allwe're planning on building Keras bindings for DL4J. Is anyone in this thread interested in and available for contributing (part-time, remote) to that? if so, pls DM me..."], ["raver120: is there any chinese edition of this book?", "raver120 is a bot :D", "we are translating it to mandarin with oreilly", "but it won't be out for a while", "If you want more information add me on wechat", "agibsonccc", "ok", "I can point you in the right direction", "we have a wechat presence", "we also do a lot of business in china", "thanks a lot", "i begin to learn dl4j for a little days, and  have lots of questions to ask.  ", "thanks for your patiences", "wechat?the Chinese IM tool from Tecent?@agibsonccc", "Yes I use wechat actively", "I was just in china for all of november :D", "I live in asia", "I spoke here just recently: [<-LINK->] "], ["hellow!"], ["Hi Adam", "how is it going?", "sunilkumartc: late in san francisco :D I'm passing out in a few", "I know.Its day in Bangalore,India", "yup I usually live in japan", "I'm used to time zones", "1 of those things :D", "Anyways - have a good \"day\" feel free to ask questions, my colleagues are awake", "Cool.will do."]], "user": [["d4jnewbie", "tomthetrainer", "tomthetrainer", "d4jnewbie", "d4jnewbie", "AlexDBlack", "d4jnewbie", "d4jnewbie", "raver119", "raver119"], ["vedina", "agibsonccc", "agibsonccc"], ["relue", "EdeMeijer", "relue", "EdeMeijer", "EdeMeijer", "agibsonccc", "agibsonccc", "relue", "AlexDBlack", "relue", "relue", "EdeMeijer"], ["crockpotveggies", "AlexDBlack", "AlexDBlack", "crockpotveggies", "daredemo", "AlexDBlack", "crockpotveggies", "AlexDBlack", "crockpotveggies", "crockpotveggies", "AlexDBlack", "AlexDBlack", "crockpotveggies"], ["dmmiller612", "raver119", "dmmiller612", "agibsonccc", "dmmiller612"], ["xuzhongxing", "agibsonccc", "agibsonccc", "xuzhongxing", "xuzhongxing", "xuzhongxing", "xuzhongxing", "xuzhongxing"], ["jvence", "agibsonccc", "agibsonccc", "jvence", "agibsonccc", "agibsonccc", "jvence", "agibsonccc", "agibsonccc", "jvence", "agibsonccc"], ["PhavMakara_twitter", "agibsonccc", "agibsonccc", "PhavMakara_twitter", "PhavMakara_twitter", "agibsonccc", "agibsonccc", "agibsonccc"], ["PhavMakara_twitter", "raver119", "PhavMakara_twitter", "PhavMakara_twitter", "AlexDBlack", "AlexDBlack", "PhavMakara_twitter"], ["xuzhongxing", "AlexDBlack", "AlexDBlack", "AlexDBlack", "xuzhongxing", "xuzhongxing", "AlexDBlack", "AlexDBlack", "AlexDBlack", "xuzhongxing", "xuzhongxing", "AlexDBlack", "xuzhongxing"], ["daredemo", "raver119", "raver119", "daredemo", "JosephCatrambone", "JosephCatrambone", "daredemo", "JosephCatrambone", "JosephCatrambone", "daredemo", "daredemo"], ["royee17", "raver119", "raver119", "royee17", "raver119"], ["thewzhang", "AlexDBlack", "AlexDBlack", "thewzhang", "AlexDBlack", "thewzhang", "AlexDBlack"], ["daredemo", "AlexDBlack", "AlexDBlack", "AlexDBlack", "AlexDBlack", "daredemo", "AlexDBlack", "daredemo", "daredemo", "AlexDBlack", "AlexDBlack", "daredemo", "AlexDBlack"], ["daredemo", "Paranaix", "daredemo", "Paranaix", "daredemo", "Paranaix", "Paranaix", "daredemo", "daredemo", "daredemo"], ["AlexDBlack", "daredemo", "AlexDBlack", "daredemo", "AlexDBlack"], ["borjka", "AlexDBlack", "fahman", "borjka", "AlexDBlack", "borjka", "AlexDBlack", "AlexDBlack", "borjka"], ["ptah23", "raver119", "ptah23", "ptah23"], ["xywen4buct", "agibsonccc", "xywen4buct", "agibsonccc", "agibsonccc", "agibsonccc", "xywen4buct", "agibsonccc", "xywen4buct", "agibsonccc", "xywen4buct", "agibsonccc", "xywen4buct", "agibsonccc", "xywen4buct", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "xywen4buct", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "xywen4buct"], ["fahman", "AlexDBlack", "fahman", "fahman", "AlexDBlack", "fahman"], ["indsak", "AlexDBlack", "indsak", "indsak", "AlexDBlack", "AlexDBlack", "indsak"], ["benqua", "nyghtowl"], ["dan-lind", "agibsonccc", "agibsonccc"], ["TrentWDB", "TrentWDB"], ["iw876", "mrseven7seven", "raver119", "raver119", "iw876", "raver119", "raver119", "iw876"], ["someonedeep", "EdeMeijer"], ["xuzonghan", "raver119", "raver119", "agibsonccc", "raver119", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "xuzonghan"], ["dan-lind", "agibsonccc"], ["truevines", "agibsonccc", "agibsonccc", "truevines", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "truevines", "truevines", "agibsonccc", "agibsonccc", "agibsonccc", "truevines"], ["crockpotveggies", "saudet"], ["AllenWGX", "agibsonccc", "agibsonccc", "agibsonccc", "AllenWGX"], ["saurabhgangurde", "AlexDBlack", "saurabhgangurde"], ["qq95538", "qq95538", "qq95538"], ["yuimo123", "kepricon", "raver119", "raver119", "yuimo123", "raver119", "raver119", "kepricon", "yuimo123", "yuimo123"], ["Oscarlight"], ["jageshmaharjan", "agibsonccc", "agibsonccc", "agibsonccc", "jageshmaharjan"], ["hakmesyo", "agibsonccc", "agibsonccc", "hakmesyo", "agibsonccc", "agibsonccc", "agibsonccc", "hakmesyo", "agibsonccc", "hakmesyo"], ["hakmesyo", "agibsonccc", "raver119", "raver119", "agibsonccc", "hakmesyo", "agibsonccc", "hakmesyo", "hakmesyo"], ["ambarishpande", "AlexDBlack"], ["v-mostafapour", "v-mostafapour", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "v-mostafapour"], ["CubeMaster007", "agibsonccc", "agibsonccc"], ["bhomass", "raver119"], ["yuimo123", "raver119", "raver119", "agibsonccc", "raver119", "yuimo123", "agibsonccc", "agibsonccc", "raver119", "yuimo123", "agibsonccc", "agibsonccc", "raver119", "agibsonccc", "yuimo123"], ["robertlee2k", "EdeMeijer", "EdeMeijer", "robertlee2k"], ["bhomass", "raver119", "raver119", "raver119", "bhomass", "raver119"], ["mansiisnam", "AlexDBlack", "mansiisnam"], ["anandundavia", "anandundavia", "agibsonccc", "agibsonccc", "anandundavia"], ["yilaguan"], ["mohanad96", "mohanad96"], ["volkanagun"], ["bogdanteleaga"], ["awongBisco"], ["scne"], ["ptah23"], ["liulhdarks"], ["Angelus1383"], ["Bren077s"], ["liulhdarks", "agibsonccc", "raver119", "saudet", "liulhdarks", "saudet", "liulhdarks"], ["gguogguo11", "agibsonccc", "agibsonccc", "agibsonccc"], ["KonceptGeek", "AlexDBlack", "AlexDBlack", "KonceptGeek", "AlexDBlack", "KonceptGeek"], ["Marcteen", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "Marcteen", "Marcteen", "agibsonccc", "agibsonccc"], ["Lancer66", "agibsonccc", "agibsonccc", "raver119", "agibsonccc", "Lancer66", "Lancer66", "agibsonccc", "agibsonccc", "Lancer66"], ["gks141270", "agibsonccc", "agibsonccc", "gks141270", "gks141270", "agibsonccc", "gks141270", "gks141270"], ["enache2004", "agibsonccc", "enache2004", "agibsonccc", "enache2004", "agibsonccc", "agibsonccc", "agibsonccc", "enache2004", "enache2004", "agibsonccc"], ["CHemauer", "CHemauer", "EdeMeijer", "EdeMeijer", "EdeMeijer", "EdeMeijer", "EdeMeijer", "CHemauer", "AlexDBlack", "AlexDBlack", "CHemauer"], ["araymer", "agibsonccc", "araymer", "agibsonccc", "agibsonccc", "araymer", "agibsonccc"], ["anchitkolla", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "anchitkolla", "anchitkolla"], ["rmuchev", "agibsonccc", "rmuchev", "rmuchev", "agibsonccc", "rmuchev"], ["bhomass", "raver119", "raver119", "bhomass", "raver119", "bhomass", "raver119", "bhomass"], ["xtuyaowu", "agibsonccc", "agibsonccc", "raver119", "agibsonccc", "agibsonccc"], ["bleuosun", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "bleuosun", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "bleuosun", "agibsonccc", "bleuosun", "bleuosun"], ["djKooks", "raver119", "agibsonccc", "agibsonccc", "djKooks", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "djKooks", "djKooks", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "djKooks"], ["daredemo", "AlexDBlack", "AlexDBlack", "daredemo", "AlexDBlack", "daredemo", "AlexDBlack", "daredemo", "AlexDBlack", "AlexDBlack", "daredemo", "AlexDBlack", "daredemo", "AlexDBlack"], ["rahulahuja16", "raver119", "raver119", "rahulahuja16", "raver119", "raver119", "rahulahuja16", "raver119", "raver119", "rahulahuja16", "raver119", "rahulahuja16", "raver119"], ["Ettrai", "nyghtowl", "tomthetrainer", "tomthetrainer", "Ettrai", "nyghtowl", "Ettrai", "nyghtowl", "Ettrai", "nyghtowl", "Ettrai", "Ettrai", "raver119", "Ettrai"], ["thhart", "agibsonccc", "thhart", "agibsonccc", "agibsonccc", "agibsonccc"], ["chrisvnicholson"], ["yuimo123", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "yuimo123", "agibsonccc", "agibsonccc", "agibsonccc", "yuimo123", "yuimo123", "yuimo123", "AllenWGX", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc"], ["1151738113"], ["sunilkumartc", "sunilkumartc", "agibsonccc", "sunilkumartc", "agibsonccc", "agibsonccc", "agibsonccc", "agibsonccc", "sunilkumartc"]], "dialog_label": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "sen_label": [["OQ", "QE", "SA", "NF", "QE", "QA", "QE", "QE", "QA", "AE"], ["OQ", "QA", "SA"], ["OQ", "QA", "AE", "AE", "AE", "AE", "AE", "GG", "AE", "AE", "AE", "AE"], ["OQ", "SA", "JK", "QE", "QA", "AE", "QE", "QA", "AE", "QE", "QA", "AE", "PF"], ["OQ", "QA", "QE", "QA", "GG"], ["OQ", "QA", "AE", "AE", "AE", "AE", "GG", "AE"], ["OQ", "QA", "SA", "QE", "QA", "SA", "QE", "QA", "SA", "UF", "SA"], ["OQ", "SA", "SA", "QE", "AE", "QA", "AE", "AE"], ["OQ", "QA", "QE", "QE", "QA", "QA", "GG"], ["OQ", "QA", "QA", "QA", "GG", "AE", "AE", "AE", "AE", "PF", "QE", "QA", "PF"], ["OQ", "QA", "AE", "AE", "AE", "SA", "QE", "QA", "AE", "AE", "AE"], ["OQ", "QA", "AE", "QE", "QA"], ["OQ", "QA", "SA", "PF", "AE", "PF", "AE"], ["OQ", "QA", "AE", "SA", "QE", "QE", "QE", "QA", "QE", "QA", "AE", "PF", "AE"], ["OQ", "SA", "QE", "QA", "QE", "QA", "QE", "QA", "QE", "QE"], ["OQ", "QE", "QA", "AE", "SA"], ["OQ", "QA", "QE", "QE", "QA", "AE", "QA", "AE", "PF"], ["OQ", "QA", "QE", "AE"], ["OQ", "SA", "QE", "QA", "QE", "QE", "QA", "SA", "AE", "AE", "AE", "SA", "QE", "QE", "QA", "RA", "AE", "AE", "AE", "AE", "AE", "AE", "AE", "AE", "AE", "AE", "GG"], ["OQ", "QA", "NF", "AE", "AE", "PF"], ["OQ", "QE", "QA", "QE", "QA", "SA", "UF"], ["OQ", "QA"], ["OQ", "RA", "AE"], ["OQ", "GG"], ["GG", "GG", "RA", "AE", "OQ", "AE", "SA", "GG"], ["OQ", "SA"], ["OQ", "QA", "AE", "AE", "AE", "AE", "AE", "AE", "AE", "AE", "AE"], ["OQ", "QA"], ["OQ", "QE", "AE", "QA", "AE", "AE", "AE", "AE", "AE", "AE", "SA", "AE", "GG", "AE", "AE", "AE", "GG"], ["OQ", "QA"], ["OQ", "QA", "AE", "SA", "UF"], ["OQ", "SA", "AE"], ["GG", "AE", "PF"], ["OQ", "SA", "AE", "AE", "AE", "QE", "JK", "SA", "GG", "QA"], ["OQ"], ["OQ", "QA", "SA", "RA", "AE"], ["OQ", "JK", "SA", "UF", "SA", "AE", "AE", "GG", "AE", "AE"], ["OQ", "SA", "SA", "JK", "SA", "PF", "SA", "JK", "PF"], ["OQ", "QE"], ["GG", "OQ", "SA", "AE", "AE", "AE", "AE", "AE", "GG"], ["OQ", "QA", "QA"], ["OQ", "SA"], ["OQ", "QA", "AE", "QE", "AE", "QA", "AE", "AE", "AE", "AE", "AE", "AE", "AE", "AE", "AE"], ["OQ", "QA", "AE", "UF"], ["OQ", "QA", "SA", "AE", "GG", "AE"], ["OQ", "SA", "UF"], ["GG", "OQ", "QA", "AE", "GG"], ["OQ"], ["GG", "QE"], ["OQ"], ["OQ"], ["OQ"], ["OQ"], ["OQ"], ["OQ"], ["OQ"], ["OQ"], ["OQ", "QE", "QA", "AE", "QE", "QA", "UF"], ["OQ", "SA", "AE", "AE"], ["OQ", "QA", "QE", "QA", "SA", "UF"], ["OQ", "QA", "AE", "AE", "AE", "GG", "QE", "QA", "SA"], ["OQ", "QA", "AE", "AE", "QE", "AE", "QA", "AE", "SA", "UF"], ["OQ", "QE", "QE", "QA", "QE", "QA", "AE", "AE"], ["OQ", "QE", "QA", "SA", "AE", "JK", "AE", "AE", "AE", "AE", "AE"], ["GG", "OQ", "QA", "AE", "AE", "AE", "AE", "QE", "QA", "RA", "PF"], ["OQ", "QE", "QA", "SA", "QE", "QA", "SA"], ["OQ", "QA", "QE", "AE", "AE", "AE", "QA"], ["OQ", "QE", "QA", "QE", "QA", "GG"], ["OQ", "QE", "QE", "QA", "AE", "AE", "AE", "AE"], ["OQ", "QE", "QE", "AE", "AE", "AE"], ["OQ", "QE", "AE", "AE", "AE", "QA", "AE", "AE", "AE", "AE", "AE", "SA", "NF", "GG"], ["OQ", "GG", "GG", "QE", "QA", "AE", "AE", "AE", "AE", "AE", "AE", "AE", "AE", "AE", "AE", "QE", "AE", "GG"], ["OQ", "QE", "AE", "AE", "SA", "UF", "SA", "NF", "AE", "QE", "QA", "SA", "GG", "AE"], ["OQ", "RA", "AE", "AE", "QE", "AE", "QA", "GG", "QE", "QA", "QE", "QA", "GG"], ["OQ", "QE", "QE", "QE", "QA", "QE", "QA", "AE", "AE", "AE", "GG", "AE", "QE", "QA"], ["OQ", "QA", "QE", "QA", "AE", "AE"], ["OQ"], ["OQ", "QA", "AE", "AE", "AE", "AE", "AE", "AE", "AE", "AE", "GG", "AE", "GG", "QE", "QA", "AE", "AE", "AE"], ["GG"], ["GG", "OQ", "QA", "AE", "AE", "AE", "AE", "AE", "UF"]], "graph_edge": [[[0, 1], [1, 2], [1, 3], [3, 4], [0, 5], [5, 6], [6, 7], [7, 8], [7, 9]], [[0, 1], [1, 2]], [[0, 1], [1, 2], [2, 3], [3, 4], [0, 5], [5, 6], [6, 7], [0, 8], [8, 9], [9, 10], [10, 11]], [[0, 1], [1, 2], [1, 3], [0, 4], [2, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10], [10, 11], [11, 12]], [[0, 1], [1, 2], [2, 3], [3, 4]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6]], [[0, 1], [1, 2], [2, 3], [3, 4], [3, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10], [10, 11], [11, 12]], [[0, 1], [1, 2], [2, 3], [0, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10]], [[0, 1], [1, 2], [2, 3], [3, 4]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10], [10, 11], [11, 12]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9]], [[0, 1], [1, 2], [2, 3], [3, 4]], [[0, 1], [1, 3], [2, 4], [3, 5], [5, 6], [6, 7], [7, 8]], [[0, 1], [1, 2], [2, 3]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10], [10, 11], [11, 12], [12, 13], [13, 14], [14, 15], [15, 16], [16, 17], [17, 18], [18, 19], [19, 20], [20, 21], [21, 22], [22, 23], [23, 24], [24, 25], [25, 26]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6]], [[0, 1]], [[0, 1], [1, 2]], [0], [[4, 5], [5, 6], [6, 7]], [[0, 1]], [[0, 1], [1, 2], [0, 3], [2, 4], [3, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10]], [[0, 1]], [[0, 1], [1, 2], [2, 3], [3, 4], [3, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10], [10, 11], [11, 12], [12, 13], [13, 14], [14, 15], [15, 16]], [[0, 1]], [[0, 1], [1, 2], [2, 3], [3, 4]], [[0, 1], [1, 2]], [0], [[0, 1], [0, 2], [2, 3], [3, 4], [4, 5], [5, 6], [4, 7], [7, 8], [6, 9]], [0], [[0, 1], [1, 2], [2, 3], [3, 4]], [[0, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9]], [[0, 1], [0, 2], [0, 4], [4, 5], [5, 6], [6, 7], [7, 8]], [[0, 1]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8]], [[0, 1], [1, 2]], [[0, 1]], [[0, 1], [1, 2], [0, 3], [2, 4], [3, 5], [5, 6], [6, 7], [4, 8], [7, 9], [9, 10], [10, 11], [9, 12], [12, 13], [13, 14]], [[0, 1], [1, 2], [2, 3]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5]], [[0, 1], [1, 2]], [[0, 1], [1, 2], [2, 3], [3, 4]], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [[0, 1], [0, 2], [0, 3], [3, 4], [4, 5], [5, 6]], [[0, 1], [1, 2], [2, 3]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [1, 6], [6, 7], [7, 8]], [[0, 1], [1, 2], [0, 3], [2, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10]], [[0, 1], [1, 2], [2, 3], [2, 4], [4, 5], [5, 6]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5]], [[0, 1], [1, 2], [2, 3], [0, 4], [4, 5], [5, 6], [6, 7]], [[0, 1], [1, 2], [1, 3], [0, 3], [3, 4], [4, 5]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10], [10, 11], [11, 12], [12, 13]], [[0, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10], [10, 11], [11, 12], [12, 13], [13, 14], [14, 15], [15, 16], [16, 17]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10], [10, 11], [11, 12], [12, 13]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [6, 8], [8, 9], [9, 10], [10, 11], [11, 12]], [[0, 1], [0, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10], [10, 11], [11, 12], [12, 13]], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5]], [0], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8], [8, 9], [9, 10], [10, 11], [11, 12], [4, 13], [13, 14], [14, 15], [15, 16], [16, 17]], [0], [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8]]]}